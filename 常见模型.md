语义分割模型大体可以分成三类：传统 CNN 改进型、高分辨率保持型、Transformer/注意力型，以及轻量级/实时型。它们的核心差异主要在“感受野-细节保留”“计算量-速度”和“是否统一多任务”这三条轴上。下面把目前主流、代表性和最新（截至 2024-10）的模型按时间线梳理，并给出各自特点与适用场景，方便快速对比选型。

---

### 1. 传统 CNN 改进型（2015-2019）
| 模型 | 关键结构 | 优点 | 缺点 | 典型场景 |
|---|---|---|---|---|
| FCN | 全卷积+反卷积+跳连 | 结构简单、训练快 | 细节丢失、边缘粗糙 | 教学/原型验证 |
| SegNet | VGG 编码+索引上采样 | 内存省、边缘比 FCN 好 | 感受野小、小目标差 | 嵌入式/显存受限 |
| U-Net | 对称 U 形+跳连 | 小样本也能收敛、医学领域标杆 | 计算量随输入线性涨 | 医学影像、工业质检 |
| U-Net++ | 密集跳连+嵌套 U | 边缘更锐利 | 参数量翻倍 | 医学、精细农业 |
| DeepLabv3+ | 空洞空间金字塔池化(ASPP)+解码器 | 多尺度上下文强、工业落地最多 | 重、慢、吃显存 | 离线精处理、遥感 |
| PSPNet | 全局金字塔池化 | 场景解析好 | 同 DeepLab，资源大户 | 城市场景解析 |

> 结论：这一阶段模型把“多尺度上下文”推到较高水平，但普遍牺牲速度，对实时应用不友好 。

---

### 2. 高分辨率保持型（2019-2022）
| 模型 | 关键结构 | 优点 | 缺点 | 典型场景 |
|---|---|---|---|---|
| HRNet | 并行多分辨率子网+反复融合 | 全程高分辨率、细节保留最佳 | 模型大、推理慢 | 高精度测绘、光伏提取 |
| GC-Net | 全局上下文模块嵌入 | 轻量版 HRNet、速度稍快 | 边缘略逊 | 遥感、道路提取 |

> 结论：HRNet 系列把“空间细节”做到极致，代价是计算量；适合对几何精度要求极高的专业领域 。

---

### 3. Transformer / 注意力统一型（2021-2024）
| 模型 | 关键结构 | 优点 | 缺点 | 典型场景 |
|---|---|---|---|---|
| Swin-U/SegFormer | 分层窗口注意力 | 全局感受野、线性计算 | 语义强、实例弱 | 通用语义分割 |
| Mask2Former | 掩码注意力 Transformer，统一“语义+实例+全景” | 三任务 SoTA、开源齐全 | 训练资源爆炸 | 研究/多任务平台 |
| MaxViT | 局部+全局双重注意力 | 局部细节+全局上下文 | 实现复杂、重 | 视觉通用 backbone |
| DINOv2 | ViT 自监督预训练 | 无需标签、特征迁移性强 | 需微调、非专用分割 | 少标签场景、泛科研 |

> 结论：Transformer 路线最大贡献是“全局上下文+多任务统一”，但训练和推理成本最高；工业落地通常只做语义分支 。

---

### 4. 轻量/实时型（2018-2024）
| 模型 | 关键结构 | 优点 | 缺点 | 典型场景 |
|---|---|---|---|---|
| BiSeNetV2 | 细节分支+语义分支双路 | 1080p 实时（>50 fps） | 精度比 DeepLab 低 3-4 mIoU | 车载、移动端 |
| STDC | 短距密集连接 | 更快、参数量 < 2 M | 边缘略粗糙 | 手机、AR 眼镜 |
| CGNet | 上下文引导块+注意力 | 仅 0.5 M 参数 | 极低算力芯片可跑 | 无人机、智能硬件 |

> 结论：轻量模型通过“双分支”或“早下采样+后期精炼”策略，把 1080p 推理拉到 30-100 fps，适合边缘端 。

---

### 5. 选型速查表
1. **医学/小样本** → U-Net 系列（U-Net/U-Net++）  
2. **离线高精度** → DeepLabv3+ / HRNet  
3. **车载/实时** → BiSeNetV2 / STDC  
4. **多任务统一（科研）** → Mask2Former  
5. **少标签/自监督** → DINOv2 + 轻量解码头  

一句话总结：  
“要精度选 HRNet/DeepLab，要速度选 BiSeNet/STDC，要全能选 Mask2Former，要自监督选 DINOv2，医学就用 U-Net。”
